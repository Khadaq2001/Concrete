{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qinxianhan/.conda/envs/singleCell/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import utils\n",
    "import numpy as n\n",
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import anndata as ad\n",
    "from torch import nn\n",
    "from trainer import concrete_trainer, MLP_trainer\n",
    "from network import MLP\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5ad_path = \"../../data/filtered_hg19.h5ad\"\n",
    "device = utils.get_device()\n",
    "#device = torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anndata_load(file_path):\n",
    "    \"\"\"Load anndata, with file_path containing mtx file\"\"\"\n",
    "    adata = sc.read_10x_mtx(file_path, var_names='gene_symbols')\n",
    "    adata.var_names_make_unique()\n",
    "    return adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 2638 × 3000\n",
       "    obs: 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt'\n",
       "    var: 'gene_ids', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_variable', 'highly_variable_rank', 'means', 'variances', 'variances_norm'\n",
       "    uns: 'hvg', 'log1p'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata = sc.read_h5ad(h5ad_path )\n",
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_top = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = n_top\n",
    "hidden_dim = [128, 256]\n",
    "out_dim = adata.shape[1]\n",
    "lr  = 1e-3\n",
    "epochs = 256\n",
    "weight_decay = 0\n",
    "loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qinxianhan/.conda/envs/singleCell/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py:62: UserWarning: `flavor='seurat_v3'` expects raw count data, but non-integers were found.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2111, 256)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sc.pp.highly_variable_genes(adata, n_top_genes=n_top, flavor='seurat_v3')\n",
    "adata_train, adata_test = utils.train_test_split(adata, test_size=0.2)\n",
    "cr_train = adata_train[:, adata.var['highly_variable']]\n",
    "cr_test = adata_test[:, adata.var['highly_variable']]\n",
    "cr_train.shape, cr_test.shape\n",
    "cr_traindata = utils.data_loader(cr_train, batch_size=128, shuffle=False)\n",
    "input_train = utils.data_loader(adata_train, batch_size=128, shuffle=False)\n",
    "cr_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 ; Loss: 0.34364; Time: 0.05 s\n",
      "Epoch: 2 ; Loss: 0.20232; Time: 0.08 s\n",
      "Epoch: 3 ; Loss: 0.17731; Time: 0.12 s\n",
      "Epoch: 4 ; Loss: 0.16520; Time: 0.16 s\n",
      "Epoch: 5 ; Loss: 0.16017; Time: 0.20 s\n",
      "Epoch: 6 ; Loss: 0.15790; Time: 0.24 s\n",
      "Epoch: 7 ; Loss: 0.15658; Time: 0.28 s\n",
      "Epoch: 8 ; Loss: 0.15540; Time: 0.32 s\n",
      "Epoch: 9 ; Loss: 0.15412; Time: 0.36 s\n",
      "Epoch: 10 ; Loss: 0.15288; Time: 0.40 s\n",
      "Epoch: 11 ; Loss: 0.15186; Time: 0.43 s\n",
      "Epoch: 12 ; Loss: 0.15097; Time: 0.47 s\n",
      "Epoch: 13 ; Loss: 0.15015; Time: 0.51 s\n",
      "Epoch: 14 ; Loss: 0.14934; Time: 0.55 s\n",
      "Epoch: 15 ; Loss: 0.14856; Time: 0.59 s\n",
      "Epoch: 16 ; Loss: 0.14779; Time: 0.63 s\n",
      "Epoch: 17 ; Loss: 0.14707; Time: 0.66 s\n",
      "Epoch: 18 ; Loss: 0.14639; Time: 0.70 s\n",
      "Epoch: 19 ; Loss: 0.14571; Time: 0.74 s\n",
      "Epoch: 20 ; Loss: 0.14505; Time: 0.78 s\n",
      "Epoch: 21 ; Loss: 0.14443; Time: 0.81 s\n",
      "Epoch: 22 ; Loss: 0.14381; Time: 0.85 s\n",
      "Epoch: 23 ; Loss: 0.14317; Time: 0.89 s\n",
      "Epoch: 24 ; Loss: 0.14257; Time: 0.93 s\n",
      "Epoch: 25 ; Loss: 0.14195; Time: 0.97 s\n",
      "Epoch: 26 ; Loss: 0.14135; Time: 1.00 s\n",
      "Epoch: 27 ; Loss: 0.14077; Time: 1.04 s\n",
      "Epoch: 28 ; Loss: 0.14021; Time: 1.08 s\n",
      "Epoch: 29 ; Loss: 0.13969; Time: 1.12 s\n",
      "Epoch: 30 ; Loss: 0.13923; Time: 1.16 s\n",
      "Epoch: 31 ; Loss: 0.13889; Time: 1.20 s\n",
      "Epoch: 32 ; Loss: 0.13888; Time: 1.23 s\n",
      "Epoch: 33 ; Loss: 0.13955; Time: 1.27 s\n",
      "Epoch: 34 ; Loss: 0.13866; Time: 1.31 s\n",
      "Epoch: 35 ; Loss: 0.13698; Time: 1.35 s\n",
      "Epoch: 36 ; Loss: 0.13642; Time: 1.39 s\n",
      "Epoch: 37 ; Loss: 0.13586; Time: 1.42 s\n",
      "Epoch: 38 ; Loss: 0.13543; Time: 1.46 s\n",
      "Epoch: 39 ; Loss: 0.13501; Time: 1.50 s\n",
      "Epoch: 40 ; Loss: 0.13463; Time: 1.54 s\n",
      "Epoch: 41 ; Loss: 0.13424; Time: 1.58 s\n",
      "Epoch: 42 ; Loss: 0.13388; Time: 1.62 s\n",
      "Epoch: 43 ; Loss: 0.13352; Time: 1.66 s\n",
      "Epoch: 44 ; Loss: 0.13318; Time: 1.69 s\n",
      "Epoch: 45 ; Loss: 0.13285; Time: 1.73 s\n",
      "Epoch: 46 ; Loss: 0.13253; Time: 1.77 s\n",
      "Epoch: 47 ; Loss: 0.13222; Time: 1.81 s\n",
      "Epoch: 48 ; Loss: 0.13191; Time: 1.85 s\n",
      "Epoch: 49 ; Loss: 0.13162; Time: 1.90 s\n",
      "Epoch: 50 ; Loss: 0.13133; Time: 1.93 s\n",
      "Epoch: 51 ; Loss: 0.13106; Time: 1.98 s\n",
      "Epoch: 52 ; Loss: 0.13079; Time: 2.02 s\n",
      "Epoch: 53 ; Loss: 0.13052; Time: 2.05 s\n",
      "Epoch: 54 ; Loss: 0.13027; Time: 2.09 s\n",
      "Epoch: 55 ; Loss: 0.13003; Time: 2.14 s\n",
      "Epoch: 56 ; Loss: 0.12981; Time: 2.18 s\n",
      "Epoch: 57 ; Loss: 0.12959; Time: 2.22 s\n",
      "Epoch: 58 ; Loss: 0.12940; Time: 2.26 s\n",
      "Epoch: 59 ; Loss: 0.12925; Time: 2.30 s\n",
      "Epoch: 60 ; Loss: 0.12908; Time: 2.34 s\n",
      "Epoch: 61 ; Loss: 0.12890; Time: 2.38 s\n",
      "Epoch: 62 ; Loss: 0.12872; Time: 2.42 s\n",
      "Epoch: 63 ; Loss: 0.12858; Time: 2.46 s\n",
      "Epoch: 64 ; Loss: 0.12890; Time: 2.50 s\n",
      "Epoch: 65 ; Loss: 0.12976; Time: 2.54 s\n",
      "Epoch: 66 ; Loss: 0.12941; Time: 2.58 s\n",
      "Epoch: 67 ; Loss: 0.12785; Time: 2.62 s\n",
      "Epoch: 68 ; Loss: 0.12750; Time: 2.65 s\n",
      "Epoch: 69 ; Loss: 0.12721; Time: 2.69 s\n",
      "Epoch: 70 ; Loss: 0.12694; Time: 2.73 s\n",
      "Epoch: 71 ; Loss: 0.12675; Time: 2.77 s\n",
      "Epoch: 72 ; Loss: 0.12654; Time: 2.81 s\n",
      "Epoch: 73 ; Loss: 0.12633; Time: 2.85 s\n",
      "Epoch: 74 ; Loss: 0.12615; Time: 2.89 s\n",
      "Epoch: 75 ; Loss: 0.12595; Time: 2.93 s\n",
      "Epoch: 76 ; Loss: 0.12576; Time: 2.97 s\n",
      "Epoch: 77 ; Loss: 0.12559; Time: 3.01 s\n",
      "Epoch: 78 ; Loss: 0.12543; Time: 3.05 s\n",
      "Epoch: 79 ; Loss: 0.12525; Time: 3.09 s\n",
      "Epoch: 80 ; Loss: 0.12510; Time: 3.13 s\n",
      "Epoch: 81 ; Loss: 0.12495; Time: 3.16 s\n",
      "Epoch: 82 ; Loss: 0.12480; Time: 3.20 s\n",
      "Epoch: 83 ; Loss: 0.12464; Time: 3.24 s\n",
      "Epoch: 84 ; Loss: 0.12448; Time: 3.28 s\n",
      "Epoch: 85 ; Loss: 0.12433; Time: 3.32 s\n",
      "Epoch: 86 ; Loss: 0.12414; Time: 3.36 s\n",
      "Epoch: 87 ; Loss: 0.12398; Time: 3.40 s\n",
      "Epoch: 88 ; Loss: 0.12380; Time: 3.44 s\n",
      "Epoch: 89 ; Loss: 0.12362; Time: 3.48 s\n",
      "Epoch: 90 ; Loss: 0.12343; Time: 3.52 s\n",
      "Epoch: 91 ; Loss: 0.12326; Time: 3.56 s\n",
      "Epoch: 92 ; Loss: 0.12312; Time: 3.60 s\n",
      "Epoch: 93 ; Loss: 0.12299; Time: 3.64 s\n",
      "Epoch: 94 ; Loss: 0.12286; Time: 3.68 s\n",
      "Epoch: 95 ; Loss: 0.12273; Time: 3.72 s\n",
      "Epoch: 96 ; Loss: 0.12262; Time: 3.76 s\n",
      "Epoch: 97 ; Loss: 0.12250; Time: 3.80 s\n",
      "Epoch: 98 ; Loss: 0.12237; Time: 3.84 s\n",
      "Epoch: 99 ; Loss: 0.12226; Time: 3.88 s\n",
      "Epoch: 100 ; Loss: 0.12213; Time: 3.92 s\n",
      "Epoch: 101 ; Loss: 0.12202; Time: 3.95 s\n",
      "Epoch: 102 ; Loss: 0.12187; Time: 3.99 s\n",
      "Epoch: 103 ; Loss: 0.12177; Time: 4.03 s\n",
      "Epoch: 104 ; Loss: 0.12165; Time: 4.07 s\n",
      "Epoch: 105 ; Loss: 0.12158; Time: 4.11 s\n",
      "Epoch: 106 ; Loss: 0.12148; Time: 4.15 s\n",
      "Epoch: 107 ; Loss: 0.12139; Time: 4.19 s\n",
      "Epoch: 108 ; Loss: 0.12130; Time: 4.23 s\n",
      "Epoch: 109 ; Loss: 0.12119; Time: 4.27 s\n",
      "Epoch: 110 ; Loss: 0.12109; Time: 4.31 s\n",
      "Epoch: 111 ; Loss: 0.12100; Time: 4.35 s\n",
      "Epoch: 112 ; Loss: 0.12088; Time: 4.39 s\n",
      "Epoch: 113 ; Loss: 0.12080; Time: 4.43 s\n",
      "Epoch: 114 ; Loss: 0.12072; Time: 4.47 s\n",
      "Epoch: 115 ; Loss: 0.12061; Time: 4.51 s\n",
      "Epoch: 116 ; Loss: 0.12054; Time: 4.55 s\n",
      "Epoch: 117 ; Loss: 0.12047; Time: 4.59 s\n",
      "Epoch: 118 ; Loss: 0.12040; Time: 4.62 s\n",
      "Epoch: 119 ; Loss: 0.12037; Time: 4.66 s\n",
      "Epoch: 120 ; Loss: 0.12041; Time: 4.70 s\n",
      "Epoch: 121 ; Loss: 0.12065; Time: 4.74 s\n",
      "Epoch: 122 ; Loss: 0.12123; Time: 4.78 s\n",
      "Epoch: 123 ; Loss: 0.12208; Time: 4.81 s\n",
      "Epoch: 124 ; Loss: 0.12176; Time: 4.85 s\n",
      "Epoch: 125 ; Loss: 0.12036; Time: 4.89 s\n",
      "Epoch: 126 ; Loss: 0.12009; Time: 4.93 s\n",
      "Epoch: 127 ; Loss: 0.12000; Time: 4.97 s\n",
      "Epoch: 128 ; Loss: 0.11995; Time: 5.00 s\n",
      "Epoch: 129 ; Loss: 0.12003; Time: 5.04 s\n",
      "Epoch: 130 ; Loss: 0.12017; Time: 5.08 s\n",
      "Epoch: 131 ; Loss: 0.12035; Time: 5.12 s\n",
      "Epoch: 132 ; Loss: 0.12045; Time: 5.16 s\n",
      "Epoch: 133 ; Loss: 0.12028; Time: 5.20 s\n",
      "Epoch: 134 ; Loss: 0.11989; Time: 5.23 s\n",
      "Epoch: 135 ; Loss: 0.11934; Time: 5.27 s\n",
      "Epoch: 136 ; Loss: 0.11891; Time: 5.31 s\n",
      "Epoch: 137 ; Loss: 0.11867; Time: 5.35 s\n",
      "Epoch: 138 ; Loss: 0.11856; Time: 5.39 s\n",
      "Epoch: 139 ; Loss: 0.11852; Time: 5.43 s\n",
      "Epoch: 140 ; Loss: 0.11848; Time: 5.46 s\n",
      "Epoch: 141 ; Loss: 0.11846; Time: 5.50 s\n",
      "Epoch: 142 ; Loss: 0.11847; Time: 5.54 s\n",
      "Epoch: 143 ; Loss: 0.11841; Time: 5.58 s\n",
      "Epoch: 144 ; Loss: 0.11833; Time: 5.61 s\n",
      "Epoch: 145 ; Loss: 0.11826; Time: 5.65 s\n",
      "Epoch: 146 ; Loss: 0.11816; Time: 5.69 s\n",
      "Epoch: 147 ; Loss: 0.11802; Time: 5.73 s\n",
      "Epoch: 148 ; Loss: 0.11789; Time: 5.77 s\n",
      "Epoch: 149 ; Loss: 0.11781; Time: 5.80 s\n",
      "Epoch: 150 ; Loss: 0.11773; Time: 5.84 s\n",
      "Epoch: 151 ; Loss: 0.11771; Time: 5.88 s\n",
      "Epoch: 152 ; Loss: 0.11770; Time: 5.92 s\n",
      "Epoch: 153 ; Loss: 0.11765; Time: 5.96 s\n",
      "Epoch: 154 ; Loss: 0.11764; Time: 5.99 s\n",
      "Epoch: 155 ; Loss: 0.11762; Time: 6.03 s\n",
      "Epoch: 156 ; Loss: 0.11764; Time: 6.07 s\n",
      "Epoch: 157 ; Loss: 0.11768; Time: 6.11 s\n",
      "Epoch: 158 ; Loss: 0.11777; Time: 6.15 s\n",
      "Epoch: 159 ; Loss: 0.11789; Time: 6.19 s\n",
      "Epoch: 160 ; Loss: 0.11804; Time: 6.23 s\n",
      "Epoch: 161 ; Loss: 0.11816; Time: 6.27 s\n",
      "Epoch: 162 ; Loss: 0.11814; Time: 6.31 s\n",
      "Epoch: 163 ; Loss: 0.11790; Time: 6.34 s\n",
      "Epoch: 164 ; Loss: 0.11762; Time: 6.38 s\n",
      "Epoch: 165 ; Loss: 0.11747; Time: 6.42 s\n",
      "Epoch: 166 ; Loss: 0.11759; Time: 6.46 s\n",
      "Epoch: 167 ; Loss: 0.11787; Time: 6.50 s\n",
      "Epoch: 168 ; Loss: 0.11850; Time: 6.54 s\n",
      "Epoch: 169 ; Loss: 0.11951; Time: 6.57 s\n",
      "Epoch: 170 ; Loss: 0.12124; Time: 6.61 s\n",
      "Epoch: 171 ; Loss: 0.12420; Time: 6.65 s\n",
      "Epoch: 172 ; Loss: 0.12326; Time: 6.69 s\n",
      "Epoch: 173 ; Loss: 0.11901; Time: 6.73 s\n",
      "Epoch: 174 ; Loss: 0.11691; Time: 6.76 s\n",
      "Epoch: 175 ; Loss: 0.11633; Time: 6.80 s\n",
      "Epoch: 176 ; Loss: 0.11619; Time: 6.84 s\n",
      "Epoch: 177 ; Loss: 0.11610; Time: 6.88 s\n",
      "Epoch: 178 ; Loss: 0.11596; Time: 6.91 s\n",
      "Epoch: 179 ; Loss: 0.11581; Time: 6.95 s\n",
      "Epoch: 180 ; Loss: 0.11566; Time: 6.99 s\n",
      "Epoch: 181 ; Loss: 0.11550; Time: 7.03 s\n",
      "Epoch: 182 ; Loss: 0.11537; Time: 7.06 s\n",
      "Epoch: 183 ; Loss: 0.11527; Time: 7.10 s\n",
      "Epoch: 184 ; Loss: 0.11517; Time: 7.14 s\n",
      "Epoch: 185 ; Loss: 0.11507; Time: 7.18 s\n",
      "Epoch: 186 ; Loss: 0.11500; Time: 7.22 s\n",
      "Epoch: 187 ; Loss: 0.11494; Time: 7.26 s\n",
      "Epoch: 188 ; Loss: 0.11486; Time: 7.29 s\n",
      "Epoch: 189 ; Loss: 0.11479; Time: 7.33 s\n",
      "Epoch: 190 ; Loss: 0.11473; Time: 7.37 s\n",
      "Epoch: 191 ; Loss: 0.11469; Time: 7.41 s\n",
      "Epoch: 192 ; Loss: 0.11460; Time: 7.45 s\n",
      "Epoch: 193 ; Loss: 0.11454; Time: 7.48 s\n",
      "Epoch: 194 ; Loss: 0.11449; Time: 7.52 s\n",
      "Epoch: 195 ; Loss: 0.11445; Time: 7.56 s\n",
      "Epoch: 196 ; Loss: 0.11439; Time: 7.60 s\n",
      "Epoch: 197 ; Loss: 0.11432; Time: 7.64 s\n",
      "Epoch: 198 ; Loss: 0.11428; Time: 7.67 s\n",
      "Epoch: 199 ; Loss: 0.11423; Time: 7.71 s\n",
      "Epoch: 200 ; Loss: 0.11415; Time: 7.75 s\n",
      "Epoch: 201 ; Loss: 0.11410; Time: 7.79 s\n",
      "Epoch: 202 ; Loss: 0.11404; Time: 7.83 s\n",
      "Epoch: 203 ; Loss: 0.11399; Time: 7.86 s\n",
      "Epoch: 204 ; Loss: 0.11393; Time: 7.90 s\n",
      "Epoch: 205 ; Loss: 0.11387; Time: 7.94 s\n",
      "Epoch: 206 ; Loss: 0.11383; Time: 7.98 s\n",
      "Epoch: 207 ; Loss: 0.11378; Time: 8.02 s\n",
      "Epoch: 208 ; Loss: 0.11374; Time: 8.06 s\n",
      "Epoch: 209 ; Loss: 0.11369; Time: 8.10 s\n",
      "Epoch: 210 ; Loss: 0.11364; Time: 8.13 s\n",
      "Epoch: 211 ; Loss: 0.11359; Time: 8.17 s\n",
      "Epoch: 212 ; Loss: 0.11353; Time: 8.21 s\n",
      "Epoch: 213 ; Loss: 0.11346; Time: 8.25 s\n",
      "Epoch: 214 ; Loss: 0.11341; Time: 8.28 s\n",
      "Epoch: 215 ; Loss: 0.11336; Time: 8.32 s\n",
      "Epoch: 216 ; Loss: 0.11331; Time: 8.36 s\n",
      "Epoch: 217 ; Loss: 0.11324; Time: 8.40 s\n",
      "Epoch: 218 ; Loss: 0.11320; Time: 8.44 s\n",
      "Epoch: 219 ; Loss: 0.11317; Time: 8.48 s\n",
      "Epoch: 220 ; Loss: 0.11313; Time: 8.52 s\n",
      "Epoch: 221 ; Loss: 0.11308; Time: 8.55 s\n",
      "Epoch: 222 ; Loss: 0.11306; Time: 8.59 s\n",
      "Epoch: 223 ; Loss: 0.11300; Time: 8.63 s\n",
      "Epoch: 224 ; Loss: 0.11295; Time: 8.67 s\n",
      "Epoch: 225 ; Loss: 0.11292; Time: 8.71 s\n",
      "Epoch: 226 ; Loss: 0.11291; Time: 8.74 s\n",
      "Epoch: 227 ; Loss: 0.11288; Time: 8.78 s\n",
      "Epoch: 228 ; Loss: 0.11283; Time: 8.82 s\n",
      "Epoch: 229 ; Loss: 0.11278; Time: 8.86 s\n",
      "Epoch: 230 ; Loss: 0.11276; Time: 8.90 s\n",
      "Epoch: 231 ; Loss: 0.11271; Time: 8.93 s\n",
      "Epoch: 232 ; Loss: 0.11267; Time: 8.97 s\n",
      "Epoch: 233 ; Loss: 0.11263; Time: 9.01 s\n",
      "Epoch: 234 ; Loss: 0.11259; Time: 9.05 s\n",
      "Epoch: 235 ; Loss: 0.11255; Time: 9.09 s\n",
      "Epoch: 236 ; Loss: 0.11250; Time: 9.13 s\n",
      "Epoch: 237 ; Loss: 0.11245; Time: 9.17 s\n",
      "Epoch: 238 ; Loss: 0.11242; Time: 9.20 s\n",
      "Epoch: 239 ; Loss: 0.11238; Time: 9.24 s\n",
      "Epoch: 240 ; Loss: 0.11235; Time: 9.28 s\n",
      "Epoch: 241 ; Loss: 0.11232; Time: 9.32 s\n",
      "Epoch: 242 ; Loss: 0.11230; Time: 9.36 s\n",
      "Epoch: 243 ; Loss: 0.11227; Time: 9.39 s\n",
      "Epoch: 244 ; Loss: 0.11225; Time: 9.43 s\n",
      "Epoch: 245 ; Loss: 0.11223; Time: 9.47 s\n",
      "Epoch: 246 ; Loss: 0.11223; Time: 9.51 s\n",
      "Epoch: 247 ; Loss: 0.11218; Time: 9.55 s\n",
      "Epoch: 248 ; Loss: 0.11215; Time: 9.58 s\n",
      "Epoch: 249 ; Loss: 0.11212; Time: 9.62 s\n",
      "Epoch: 250 ; Loss: 0.11209; Time: 9.66 s\n",
      "Epoch: 251 ; Loss: 0.11209; Time: 9.70 s\n",
      "Epoch: 252 ; Loss: 0.11205; Time: 9.74 s\n",
      "Epoch: 253 ; Loss: 0.11202; Time: 9.77 s\n",
      "Epoch: 254 ; Loss: 0.11199; Time: 9.81 s\n",
      "Epoch: 255 ; Loss: 0.11195; Time: 9.85 s\n",
      "Epoch: 256 ; Loss: 0.11192; Time: 9.89 s\n"
     ]
    }
   ],
   "source": [
    "net = MLP(input_dim=input_dim, hidden_dim=hidden_dim, out_dim=out_dim,device=device)\n",
    "MLP_trainer(net, loss,cr_traindata,input_train , epochs,lr, weight_decay, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15457934141159058"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val = torch.tensor(cr_test.X.A).to(device)\n",
    "y_val = torch.tensor(adata_test.X.A).to(device)\n",
    "net.validate(x_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 2638 × 32"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset = sc.read_h5ad('./output/concrete_autoencoder.h5ad')\n",
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = subset.shape[1]\n",
    "sub_train, sub_test = utils.train_test_split(subset, test_size=0.2)\n",
    "sub_traindata = utils.data_loader(sub_train, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 ; Loss: 0.39356; Time: 0.04 s\n",
      "Epoch: 2 ; Loss: 0.25454; Time: 0.08 s\n",
      "Epoch: 3 ; Loss: 0.21202; Time: 0.11 s\n",
      "Epoch: 4 ; Loss: 0.20018; Time: 0.15 s\n",
      "Epoch: 5 ; Loss: 0.19748; Time: 0.19 s\n",
      "Epoch: 6 ; Loss: 0.19684; Time: 0.22 s\n",
      "Epoch: 7 ; Loss: 0.19649; Time: 0.26 s\n",
      "Epoch: 8 ; Loss: 0.19624; Time: 0.30 s\n",
      "Epoch: 9 ; Loss: 0.19603; Time: 0.34 s\n",
      "Epoch: 10 ; Loss: 0.19583; Time: 0.37 s\n",
      "Epoch: 11 ; Loss: 0.19566; Time: 0.41 s\n",
      "Epoch: 12 ; Loss: 0.19549; Time: 0.45 s\n",
      "Epoch: 13 ; Loss: 0.19533; Time: 0.48 s\n",
      "Epoch: 14 ; Loss: 0.19518; Time: 0.52 s\n",
      "Epoch: 15 ; Loss: 0.19503; Time: 0.56 s\n",
      "Epoch: 16 ; Loss: 0.19487; Time: 0.59 s\n",
      "Epoch: 17 ; Loss: 0.19472; Time: 0.63 s\n",
      "Epoch: 18 ; Loss: 0.19457; Time: 0.66 s\n",
      "Epoch: 19 ; Loss: 0.19442; Time: 0.70 s\n",
      "Epoch: 20 ; Loss: 0.19427; Time: 0.74 s\n",
      "Epoch: 21 ; Loss: 0.19411; Time: 0.78 s\n",
      "Epoch: 22 ; Loss: 0.19396; Time: 0.81 s\n",
      "Epoch: 23 ; Loss: 0.19380; Time: 0.85 s\n",
      "Epoch: 24 ; Loss: 0.19364; Time: 0.89 s\n",
      "Epoch: 25 ; Loss: 0.19348; Time: 0.93 s\n",
      "Epoch: 26 ; Loss: 0.19333; Time: 0.96 s\n",
      "Epoch: 27 ; Loss: 0.19316; Time: 1.00 s\n",
      "Epoch: 28 ; Loss: 0.19301; Time: 1.04 s\n",
      "Epoch: 29 ; Loss: 0.19285; Time: 1.07 s\n",
      "Epoch: 30 ; Loss: 0.19269; Time: 1.11 s\n",
      "Epoch: 31 ; Loss: 0.19254; Time: 1.15 s\n",
      "Epoch: 32 ; Loss: 0.19239; Time: 1.18 s\n",
      "Epoch: 33 ; Loss: 0.19224; Time: 1.22 s\n",
      "Epoch: 34 ; Loss: 0.19211; Time: 1.26 s\n",
      "Epoch: 35 ; Loss: 0.19195; Time: 1.29 s\n",
      "Epoch: 36 ; Loss: 0.19182; Time: 1.33 s\n",
      "Epoch: 37 ; Loss: 0.19167; Time: 1.36 s\n",
      "Epoch: 38 ; Loss: 0.19154; Time: 1.40 s\n",
      "Epoch: 39 ; Loss: 0.19140; Time: 1.44 s\n",
      "Epoch: 40 ; Loss: 0.19127; Time: 1.47 s\n",
      "Epoch: 41 ; Loss: 0.19114; Time: 1.51 s\n",
      "Epoch: 42 ; Loss: 0.19102; Time: 1.55 s\n",
      "Epoch: 43 ; Loss: 0.19088; Time: 1.58 s\n",
      "Epoch: 44 ; Loss: 0.19076; Time: 1.62 s\n",
      "Epoch: 45 ; Loss: 0.19063; Time: 1.66 s\n",
      "Epoch: 46 ; Loss: 0.19051; Time: 1.69 s\n",
      "Epoch: 47 ; Loss: 0.19038; Time: 1.73 s\n",
      "Epoch: 48 ; Loss: 0.19027; Time: 1.77 s\n",
      "Epoch: 49 ; Loss: 0.19014; Time: 1.80 s\n",
      "Epoch: 50 ; Loss: 0.19004; Time: 1.84 s\n",
      "Epoch: 51 ; Loss: 0.18992; Time: 1.88 s\n",
      "Epoch: 52 ; Loss: 0.18982; Time: 1.91 s\n",
      "Epoch: 53 ; Loss: 0.18970; Time: 1.95 s\n",
      "Epoch: 54 ; Loss: 0.18960; Time: 1.99 s\n",
      "Epoch: 55 ; Loss: 0.18949; Time: 2.02 s\n",
      "Epoch: 56 ; Loss: 0.18939; Time: 2.06 s\n",
      "Epoch: 57 ; Loss: 0.18928; Time: 2.10 s\n",
      "Epoch: 58 ; Loss: 0.18918; Time: 2.13 s\n",
      "Epoch: 59 ; Loss: 0.18907; Time: 2.17 s\n",
      "Epoch: 60 ; Loss: 0.18898; Time: 2.20 s\n",
      "Epoch: 61 ; Loss: 0.18888; Time: 2.24 s\n",
      "Epoch: 62 ; Loss: 0.18878; Time: 2.28 s\n",
      "Epoch: 63 ; Loss: 0.18869; Time: 2.31 s\n",
      "Epoch: 64 ; Loss: 0.18859; Time: 2.35 s\n",
      "Epoch: 65 ; Loss: 0.18850; Time: 2.39 s\n",
      "Epoch: 66 ; Loss: 0.18840; Time: 2.42 s\n",
      "Epoch: 67 ; Loss: 0.18831; Time: 2.46 s\n",
      "Epoch: 68 ; Loss: 0.18822; Time: 2.50 s\n",
      "Epoch: 69 ; Loss: 0.18814; Time: 2.53 s\n",
      "Epoch: 70 ; Loss: 0.18805; Time: 2.57 s\n",
      "Epoch: 71 ; Loss: 0.18796; Time: 2.61 s\n",
      "Epoch: 72 ; Loss: 0.18788; Time: 2.64 s\n",
      "Epoch: 73 ; Loss: 0.18779; Time: 2.68 s\n",
      "Epoch: 74 ; Loss: 0.18771; Time: 2.72 s\n",
      "Epoch: 75 ; Loss: 0.18762; Time: 2.75 s\n",
      "Epoch: 76 ; Loss: 0.18754; Time: 2.79 s\n",
      "Epoch: 77 ; Loss: 0.18746; Time: 2.82 s\n",
      "Epoch: 78 ; Loss: 0.18738; Time: 2.86 s\n",
      "Epoch: 79 ; Loss: 0.18730; Time: 2.90 s\n",
      "Epoch: 80 ; Loss: 0.18722; Time: 2.93 s\n",
      "Epoch: 81 ; Loss: 0.18714; Time: 2.97 s\n",
      "Epoch: 82 ; Loss: 0.18707; Time: 3.01 s\n",
      "Epoch: 83 ; Loss: 0.18698; Time: 3.04 s\n",
      "Epoch: 84 ; Loss: 0.18690; Time: 3.08 s\n",
      "Epoch: 85 ; Loss: 0.18682; Time: 3.12 s\n",
      "Epoch: 86 ; Loss: 0.18675; Time: 3.15 s\n",
      "Epoch: 87 ; Loss: 0.18667; Time: 3.19 s\n",
      "Epoch: 88 ; Loss: 0.18660; Time: 3.23 s\n",
      "Epoch: 89 ; Loss: 0.18653; Time: 3.26 s\n",
      "Epoch: 90 ; Loss: 0.18645; Time: 3.30 s\n",
      "Epoch: 91 ; Loss: 0.18638; Time: 3.33 s\n",
      "Epoch: 92 ; Loss: 0.18630; Time: 3.37 s\n",
      "Epoch: 93 ; Loss: 0.18622; Time: 3.41 s\n",
      "Epoch: 94 ; Loss: 0.18615; Time: 3.44 s\n",
      "Epoch: 95 ; Loss: 0.18609; Time: 3.48 s\n",
      "Epoch: 96 ; Loss: 0.18601; Time: 3.51 s\n",
      "Epoch: 97 ; Loss: 0.18594; Time: 3.55 s\n",
      "Epoch: 98 ; Loss: 0.18587; Time: 3.59 s\n",
      "Epoch: 99 ; Loss: 0.18580; Time: 3.63 s\n",
      "Epoch: 100 ; Loss: 0.18573; Time: 3.66 s\n",
      "Epoch: 101 ; Loss: 0.18566; Time: 3.70 s\n",
      "Epoch: 102 ; Loss: 0.18560; Time: 3.73 s\n",
      "Epoch: 103 ; Loss: 0.18552; Time: 3.77 s\n",
      "Epoch: 104 ; Loss: 0.18546; Time: 3.81 s\n",
      "Epoch: 105 ; Loss: 0.18539; Time: 3.84 s\n",
      "Epoch: 106 ; Loss: 0.18531; Time: 3.88 s\n",
      "Epoch: 107 ; Loss: 0.18525; Time: 3.92 s\n",
      "Epoch: 108 ; Loss: 0.18518; Time: 3.95 s\n",
      "Epoch: 109 ; Loss: 0.18511; Time: 3.99 s\n",
      "Epoch: 110 ; Loss: 0.18504; Time: 4.03 s\n",
      "Epoch: 111 ; Loss: 0.18497; Time: 4.06 s\n",
      "Epoch: 112 ; Loss: 0.18489; Time: 4.10 s\n",
      "Epoch: 113 ; Loss: 0.18482; Time: 4.13 s\n",
      "Epoch: 114 ; Loss: 0.18475; Time: 4.17 s\n",
      "Epoch: 115 ; Loss: 0.18469; Time: 4.21 s\n",
      "Epoch: 116 ; Loss: 0.18461; Time: 4.24 s\n",
      "Epoch: 117 ; Loss: 0.18455; Time: 4.28 s\n",
      "Epoch: 118 ; Loss: 0.18447; Time: 4.32 s\n",
      "Epoch: 119 ; Loss: 0.18442; Time: 4.35 s\n",
      "Epoch: 120 ; Loss: 0.18435; Time: 4.39 s\n",
      "Epoch: 121 ; Loss: 0.18429; Time: 4.42 s\n",
      "Epoch: 122 ; Loss: 0.18423; Time: 4.46 s\n",
      "Epoch: 123 ; Loss: 0.18417; Time: 4.50 s\n",
      "Epoch: 124 ; Loss: 0.18411; Time: 4.53 s\n",
      "Epoch: 125 ; Loss: 0.18405; Time: 4.57 s\n",
      "Epoch: 126 ; Loss: 0.18398; Time: 4.61 s\n",
      "Epoch: 127 ; Loss: 0.18392; Time: 4.64 s\n",
      "Epoch: 128 ; Loss: 0.18386; Time: 4.68 s\n",
      "Epoch: 129 ; Loss: 0.18380; Time: 4.72 s\n",
      "Epoch: 130 ; Loss: 0.18374; Time: 4.75 s\n",
      "Epoch: 131 ; Loss: 0.18368; Time: 4.79 s\n",
      "Epoch: 132 ; Loss: 0.18362; Time: 4.83 s\n",
      "Epoch: 133 ; Loss: 0.18356; Time: 4.86 s\n",
      "Epoch: 134 ; Loss: 0.18350; Time: 4.90 s\n",
      "Epoch: 135 ; Loss: 0.18344; Time: 4.94 s\n",
      "Epoch: 136 ; Loss: 0.18339; Time: 4.97 s\n",
      "Epoch: 137 ; Loss: 0.18333; Time: 5.01 s\n",
      "Epoch: 138 ; Loss: 0.18327; Time: 5.04 s\n",
      "Epoch: 139 ; Loss: 0.18322; Time: 5.08 s\n",
      "Epoch: 140 ; Loss: 0.18317; Time: 5.12 s\n",
      "Epoch: 141 ; Loss: 0.18310; Time: 5.15 s\n",
      "Epoch: 142 ; Loss: 0.18305; Time: 5.19 s\n",
      "Epoch: 143 ; Loss: 0.18299; Time: 5.23 s\n",
      "Epoch: 144 ; Loss: 0.18293; Time: 5.26 s\n",
      "Epoch: 145 ; Loss: 0.18288; Time: 5.30 s\n",
      "Epoch: 146 ; Loss: 0.18282; Time: 5.34 s\n",
      "Epoch: 147 ; Loss: 0.18277; Time: 5.37 s\n",
      "Epoch: 148 ; Loss: 0.18271; Time: 5.41 s\n",
      "Epoch: 149 ; Loss: 0.18266; Time: 5.45 s\n",
      "Epoch: 150 ; Loss: 0.18260; Time: 5.48 s\n",
      "Epoch: 151 ; Loss: 0.18255; Time: 5.52 s\n",
      "Epoch: 152 ; Loss: 0.18250; Time: 5.56 s\n",
      "Epoch: 153 ; Loss: 0.18244; Time: 5.59 s\n",
      "Epoch: 154 ; Loss: 0.18240; Time: 5.63 s\n",
      "Epoch: 155 ; Loss: 0.18234; Time: 5.66 s\n",
      "Epoch: 156 ; Loss: 0.18229; Time: 5.70 s\n",
      "Epoch: 157 ; Loss: 0.18224; Time: 5.74 s\n",
      "Epoch: 158 ; Loss: 0.18219; Time: 5.77 s\n",
      "Epoch: 159 ; Loss: 0.18213; Time: 5.81 s\n",
      "Epoch: 160 ; Loss: 0.18208; Time: 5.85 s\n",
      "Epoch: 161 ; Loss: 0.18203; Time: 5.88 s\n",
      "Epoch: 162 ; Loss: 0.18198; Time: 5.92 s\n",
      "Epoch: 163 ; Loss: 0.18192; Time: 5.96 s\n",
      "Epoch: 164 ; Loss: 0.18188; Time: 5.99 s\n",
      "Epoch: 165 ; Loss: 0.18182; Time: 6.03 s\n",
      "Epoch: 166 ; Loss: 0.18177; Time: 6.06 s\n",
      "Epoch: 167 ; Loss: 0.18173; Time: 6.10 s\n",
      "Epoch: 168 ; Loss: 0.18167; Time: 6.14 s\n",
      "Epoch: 169 ; Loss: 0.18163; Time: 6.17 s\n",
      "Epoch: 170 ; Loss: 0.18157; Time: 6.21 s\n",
      "Epoch: 171 ; Loss: 0.18153; Time: 6.25 s\n",
      "Epoch: 172 ; Loss: 0.18148; Time: 6.28 s\n",
      "Epoch: 173 ; Loss: 0.18143; Time: 6.32 s\n",
      "Epoch: 174 ; Loss: 0.18138; Time: 6.35 s\n",
      "Epoch: 175 ; Loss: 0.18133; Time: 6.39 s\n",
      "Epoch: 176 ; Loss: 0.18128; Time: 6.43 s\n",
      "Epoch: 177 ; Loss: 0.18124; Time: 6.46 s\n",
      "Epoch: 178 ; Loss: 0.18118; Time: 6.50 s\n",
      "Epoch: 179 ; Loss: 0.18114; Time: 6.54 s\n",
      "Epoch: 180 ; Loss: 0.18109; Time: 6.57 s\n",
      "Epoch: 181 ; Loss: 0.18104; Time: 6.61 s\n",
      "Epoch: 182 ; Loss: 0.18100; Time: 6.65 s\n",
      "Epoch: 183 ; Loss: 0.18095; Time: 6.68 s\n",
      "Epoch: 184 ; Loss: 0.18090; Time: 6.72 s\n",
      "Epoch: 185 ; Loss: 0.18085; Time: 6.75 s\n",
      "Epoch: 186 ; Loss: 0.18081; Time: 6.79 s\n",
      "Epoch: 187 ; Loss: 0.18076; Time: 6.83 s\n",
      "Epoch: 188 ; Loss: 0.18072; Time: 6.86 s\n",
      "Epoch: 189 ; Loss: 0.18066; Time: 6.90 s\n",
      "Epoch: 190 ; Loss: 0.18062; Time: 6.94 s\n",
      "Epoch: 191 ; Loss: 0.18057; Time: 6.97 s\n",
      "Epoch: 192 ; Loss: 0.18053; Time: 7.01 s\n",
      "Epoch: 193 ; Loss: 0.18048; Time: 7.05 s\n",
      "Epoch: 194 ; Loss: 0.18044; Time: 7.08 s\n",
      "Epoch: 195 ; Loss: 0.18038; Time: 7.12 s\n",
      "Epoch: 196 ; Loss: 0.18034; Time: 7.15 s\n",
      "Epoch: 197 ; Loss: 0.18030; Time: 7.19 s\n",
      "Epoch: 198 ; Loss: 0.18025; Time: 7.23 s\n",
      "Epoch: 199 ; Loss: 0.18021; Time: 7.26 s\n",
      "Epoch: 200 ; Loss: 0.18016; Time: 7.30 s\n",
      "Epoch: 201 ; Loss: 0.18012; Time: 7.34 s\n",
      "Epoch: 202 ; Loss: 0.18007; Time: 7.37 s\n",
      "Epoch: 203 ; Loss: 0.18003; Time: 7.41 s\n",
      "Epoch: 204 ; Loss: 0.17998; Time: 7.44 s\n",
      "Epoch: 205 ; Loss: 0.17994; Time: 7.48 s\n",
      "Epoch: 206 ; Loss: 0.17990; Time: 7.52 s\n",
      "Epoch: 207 ; Loss: 0.17985; Time: 7.55 s\n",
      "Epoch: 208 ; Loss: 0.17982; Time: 7.59 s\n",
      "Epoch: 209 ; Loss: 0.17977; Time: 7.63 s\n",
      "Epoch: 210 ; Loss: 0.17972; Time: 7.66 s\n",
      "Epoch: 211 ; Loss: 0.17967; Time: 7.70 s\n",
      "Epoch: 212 ; Loss: 0.17963; Time: 7.74 s\n",
      "Epoch: 213 ; Loss: 0.17959; Time: 7.77 s\n",
      "Epoch: 214 ; Loss: 0.17955; Time: 7.81 s\n",
      "Epoch: 215 ; Loss: 0.17950; Time: 7.84 s\n",
      "Epoch: 216 ; Loss: 0.17947; Time: 7.88 s\n",
      "Epoch: 217 ; Loss: 0.17942; Time: 7.92 s\n",
      "Epoch: 218 ; Loss: 0.17938; Time: 7.95 s\n",
      "Epoch: 219 ; Loss: 0.17933; Time: 7.99 s\n",
      "Epoch: 220 ; Loss: 0.17929; Time: 8.03 s\n",
      "Epoch: 221 ; Loss: 0.17924; Time: 8.06 s\n",
      "Epoch: 222 ; Loss: 0.17922; Time: 8.10 s\n",
      "Epoch: 223 ; Loss: 0.17916; Time: 8.13 s\n",
      "Epoch: 224 ; Loss: 0.17912; Time: 8.17 s\n",
      "Epoch: 225 ; Loss: 0.17908; Time: 8.21 s\n",
      "Epoch: 226 ; Loss: 0.17904; Time: 8.24 s\n",
      "Epoch: 227 ; Loss: 0.17900; Time: 8.28 s\n",
      "Epoch: 228 ; Loss: 0.17896; Time: 8.32 s\n",
      "Epoch: 229 ; Loss: 0.17892; Time: 8.35 s\n",
      "Epoch: 230 ; Loss: 0.17888; Time: 8.39 s\n",
      "Epoch: 231 ; Loss: 0.17884; Time: 8.42 s\n",
      "Epoch: 232 ; Loss: 0.17879; Time: 8.46 s\n",
      "Epoch: 233 ; Loss: 0.17876; Time: 8.50 s\n",
      "Epoch: 234 ; Loss: 0.17872; Time: 8.53 s\n",
      "Epoch: 235 ; Loss: 0.17868; Time: 8.57 s\n",
      "Epoch: 236 ; Loss: 0.17863; Time: 8.61 s\n",
      "Epoch: 237 ; Loss: 0.17860; Time: 8.64 s\n",
      "Epoch: 238 ; Loss: 0.17855; Time: 8.68 s\n",
      "Epoch: 239 ; Loss: 0.17851; Time: 8.72 s\n",
      "Epoch: 240 ; Loss: 0.17848; Time: 8.75 s\n",
      "Epoch: 241 ; Loss: 0.17844; Time: 8.79 s\n",
      "Epoch: 242 ; Loss: 0.17840; Time: 8.82 s\n",
      "Epoch: 243 ; Loss: 0.17835; Time: 8.86 s\n",
      "Epoch: 244 ; Loss: 0.17831; Time: 8.90 s\n",
      "Epoch: 245 ; Loss: 0.17828; Time: 8.93 s\n",
      "Epoch: 246 ; Loss: 0.17824; Time: 8.97 s\n",
      "Epoch: 247 ; Loss: 0.17819; Time: 9.01 s\n",
      "Epoch: 248 ; Loss: 0.17816; Time: 9.04 s\n",
      "Epoch: 249 ; Loss: 0.17812; Time: 9.08 s\n",
      "Epoch: 250 ; Loss: 0.17808; Time: 9.12 s\n",
      "Epoch: 251 ; Loss: 0.17804; Time: 9.15 s\n",
      "Epoch: 252 ; Loss: 0.17800; Time: 9.19 s\n",
      "Epoch: 253 ; Loss: 0.17796; Time: 9.23 s\n",
      "Epoch: 254 ; Loss: 0.17792; Time: 9.26 s\n",
      "Epoch: 255 ; Loss: 0.17789; Time: 9.30 s\n",
      "Epoch: 256 ; Loss: 0.17784; Time: 9.33 s\n"
     ]
    }
   ],
   "source": [
    "net = MLP(input_dim=input_dim, hidden_dim=hidden_dim, out_dim=out_dim,device=device)\n",
    "MLP_trainer(net, loss,sub_traindata,input_train,epochs,lr, weight_decay, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2084445059299469"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val = torch.tensor(sub_test.X).to(device)\n",
    "net.validate(x_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = pd.read_csv('../result/filtered_set384_1.csv')\n",
    "subsubset = subset['gene_idx'].values[:32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = adata[:,subsubset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_test.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "singleCell",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
